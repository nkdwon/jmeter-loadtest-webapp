# ğŸ“š ExplicaÃ§Ã£o Completa: Testes de Performance e JMeter

## ğŸ¯ O que o Desafio MAD Pede

O desafio solicita que vocÃª:

1. **Desenvolva uma aplicaÃ§Ã£o web** (âœ… Feito - sistema de e-commerce de produtos)
2. **Realize testes nÃ£o funcionais de performance** usando Apache JMeter
3. **Simule 3 cenÃ¡rios diferentes de carga:**
   - **Carga Esparsa**: Poucos usuÃ¡rios simultÃ¢neos (situaÃ§Ã£o normal)
   - **Carga Crescente**: Aumento gradual de usuÃ¡rios (crescimento orgÃ¢nico)
   - **Rajada de Carga**: Pico sÃºbito de acessos (Black Friday, promoÃ§Ãµes)
4. **Construa e analise tabelas e grÃ¡ficos** sobre o desempenho da aplicaÃ§Ã£o

---

## ğŸ”¬ Os 4 Testes de Performance da AplicaÃ§Ã£o

Sua aplicaÃ§Ã£o possui **4 endpoints especiais** criados especificamente para estressar diferentes aspectos do sistema:

### 1. ğŸ”¥ Teste de CPU Pesado (`/heavy-cpu`)

**O que faz:**
```javascript
let x = 0
for (let i = 0; i < 50_000_000; i++) {
  x += Math.sqrt(i)
}
```

**Objetivo:**
- Simula processamento matemÃ¡tico intensivo
- Faz 50 milhÃµes de iteraÃ§Ãµes calculando raiz quadrada
- **Testa**: Capacidade de processamento da CPU do servidor

**Quando usar no JMeter:**
- Para verificar como o servidor se comporta com operaÃ§Ãµes computacionalmente caras
- Simular processamento de dados, cÃ¡lculos complexos, algoritmos pesados

**CenÃ¡rio Real:**
- Processar relatÃ³rios complexos
- Fazer cÃ¡lculos financeiros
- Aplicar algoritmos de machine learning
- CompressÃ£o/descompressÃ£o de dados

**O que observar:**
- â±ï¸ Tempo de resposta aumenta muito com muitos usuÃ¡rios simultÃ¢neos
- ğŸ”¥ Uso de CPU do servidor vai a 100%
- ğŸ“‰ Throughput (requisiÃ§Ãµes/segundo) diminui drasticamente
- âš ï¸ Servidor pode comeÃ§ar a rejeitar conexÃµes (erros 5xx)

---

### 2. â±ï¸ Teste de I/O Pesado (`/heavy-io`)

**O que faz:**
```javascript
setTimeout(() => {
  res.json({ message: 'I/O concluÃ­do' })
}, 3000) // Espera 3 segundos
```

**Objetivo:**
- Simula operaÃ§Ãµes de Input/Output bloqueantes
- Cada requisiÃ§Ã£o trava por 3 segundos antes de responder
- **Testa**: Capacidade de lidar com operaÃ§Ãµes de I/O lentas

**Quando usar no JMeter:**
- Para verificar comportamento com operaÃ§Ãµes de banco de dados lentas
- Simular consultas SQL complexas, leitura de arquivos grandes

**CenÃ¡rio Real:**
- Consulta em banco de dados nÃ£o otimizado
- Leitura de arquivos grandes do disco
- Chamadas a APIs externas lentas
- Upload/download de arquivos

**O que observar:**
- â³ Tempo de resposta: sempre ~3 segundos por requisiÃ§Ã£o
- ğŸ”¢ NÃºmero mÃ¡ximo de conexÃµes simultÃ¢neas Ã© limitado
- ğŸš« Com muitos usuÃ¡rios, servidor pode atingir limite de conexÃµes
- âš ï¸ Erros de timeout podem aparecer

---

### 3. ğŸ² Teste de Delay AleatÃ³rio (`/random-delay`)

**O que faz:**
```javascript
const delay = Math.floor(Math.random() * 4000) + 1000 // 1-5 segundos
setTimeout(() => {
  res.json({ delay })
}, delay)
```

**Objetivo:**
- Simula latÃªncia variÃ¡vel e imprevisÃ­vel
- Cada requisiÃ§Ã£o demora entre 1 e 5 segundos aleatoriamente
- **Testa**: Como a aplicaÃ§Ã£o lida com tempos de resposta inconsistentes

**Quando usar no JMeter:**
- Para verificar comportamento com serviÃ§os externos instÃ¡veis
- Simular condiÃ§Ãµes de rede variÃ¡veis

**CenÃ¡rio Real:**
- APIs de terceiros com latÃªncia variÃ¡vel
- ServiÃ§os de pagamento online
- Consultas a APIs de redes sociais
- Chamadas a microsserviÃ§os com carga variÃ¡vel

**O que observar:**
- ğŸ“Š Grande variaÃ§Ã£o (desvio padrÃ£o alto) nos tempos de resposta
- ğŸ“ˆ Mediana vs MÃ©dia: valores muito diferentes
- ğŸ¯ Percentis (90%, 95%, 99%) revelam outliers
- âš ï¸ DifÃ­cil prever comportamento do sistema

---

### 4. ğŸ“Š Teste de TransferÃªncia de Dados (`/many-items`)

**O que faz:**
```javascript
const items = []
for (let i = 0; i < 50000; i++) {
  items.push({ id: i, name: 'Item ' + i })
}
res.json(items)
```

**Objetivo:**
- Retorna 50.000 itens em formato JSON
- Gera ~2-3 MB de dados por requisiÃ§Ã£o
- **Testa**: Largura de banda e capacidade de transferÃªncia de dados

**Quando usar no JMeter:**
- Para verificar performance com payloads grandes
- Simular transferÃªncia de grandes volumes de dados

**CenÃ¡rio Real:**
- Exportar relatÃ³rios grandes
- Listagem completa de produtos/usuÃ¡rios
- Download de logs
- APIs que retornam muitos dados

**O que observar:**
- ğŸŒ Uso de banda de rede aumenta drasticamente
- â±ï¸ Tempo de resposta depende da velocidade da rede
- ğŸ“‰ Throughput em KB/s ou MB/s (nÃ£o sÃ³ req/s)
- ğŸ’¾ Uso de memÃ³ria do servidor pode aumentar
- âš ï¸ PossÃ­vel erro de memÃ³ria em cenÃ¡rios extremos

---

## ğŸ§ª Como Usar o JMeter com Sua AplicaÃ§Ã£o

### Estrutura do Teste no JMeter

```
Test Plan
â”‚
â”œâ”€â”€ ğŸ“‹ Thread Group: CARGA ESPARSA
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”§ HTTP Request Defaults
â”‚   â”‚   â”œâ”€â”€ Server: localhost
â”‚   â”‚   â””â”€â”€ Port: 3000
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ ConfiguraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ Threads (UsuÃ¡rios): 10
â”‚   â”‚   â”œâ”€â”€ Ramp-Up (Tempo para iniciar todos): 30s
â”‚   â”‚   â””â”€â”€ Loop Count (RepetiÃ§Ãµes): 10
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“¨ HTTP Requests
â”‚   â”‚   â”œâ”€â”€ GET /products
â”‚   â”‚   â”œâ”€â”€ GET /status
â”‚   â”‚   â””â”€â”€ GET /products/1
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“Š Listeners (Ouvintes)
â”‚       â”œâ”€â”€ View Results Tree
â”‚       â”œâ”€â”€ Summary Report
â”‚       â”œâ”€â”€ Aggregate Report
â”‚       â””â”€â”€ Graph Results
â”‚
â”œâ”€â”€ ğŸ“‹ Thread Group: CARGA CRESCENTE
â”‚   â”œâ”€â”€ Threads: 500
â”‚   â”œâ”€â”€ Ramp-Up: 120s
â”‚   â””â”€â”€ Requests:
â”‚       â”œâ”€â”€ 40% GET /products
â”‚       â”œâ”€â”€ 20% POST /products (criar)
â”‚       â”œâ”€â”€ 20% PUT /products/{id} (atualizar)
â”‚       â”œâ”€â”€ 10% DELETE /products/{id} (deletar)
â”‚       â””â”€â”€ 10% GET /heavy-cpu
â”‚
â””â”€â”€ ğŸ“‹ Thread Group: RAJADA DE CARGA
    â”œâ”€â”€ Threads: 1000
    â”œâ”€â”€ Ramp-Up: 10s
    â””â”€â”€ Requests:
        â”œâ”€â”€ 50% GET /products
        â”œâ”€â”€ 30% GET /many-items
        â””â”€â”€ 20% GET /heavy-io
```

---

## ğŸ“‹ Passo a Passo: Configurando o JMeter

### 1ï¸âƒ£ Criar Test Plan BÃ¡sico

1. Abra o JMeter (`bin/jmeter.bat` no Windows)
2. Clique com botÃ£o direito em "Test Plan"
3. Add â†’ Threads (Users) â†’ Thread Group
4. Configure:
   - **Name**: "Carga Esparsa"
   - **Number of Threads**: 10
   - **Ramp-Up Period**: 30
   - **Loop Count**: 10

### 2ï¸âƒ£ Adicionar HTTP Request Defaults

1. Clique com botÃ£o direito no Thread Group
2. Add â†’ Config Element â†’ HTTP Request Defaults
3. Configure:
   - **Server Name**: localhost
   - **Port Number**: 3000
   - **Protocol**: http

### 3ï¸âƒ£ Adicionar RequisiÃ§Ãµes HTTP

1. Clique com botÃ£o direito no Thread Group
2. Add â†’ Sampler â†’ HTTP Request
3. Configure:
   - **Name**: "GET Products"
   - **Method**: GET
   - **Path**: /products

Repita para cada endpoint que quer testar.

### 4ï¸âƒ£ Adicionar Listeners (Visualizadores)

1. Clique com botÃ£o direito no Thread Group
2. Add â†’ Listener â†’ escolha um:
   - **Summary Report**: VisÃ£o geral das mÃ©tricas
   - **View Results Tree**: Detalhes de cada requisiÃ§Ã£o
   - **Aggregate Report**: EstatÃ­sticas detalhadas (mediana, percentis)
   - **Graph Results**: GrÃ¡fico de tempo de resposta
   - **Response Time Graph**: GrÃ¡fico mais detalhado

### 5ï¸âƒ£ Executar o Teste

1. Salve o Test Plan (Ctrl+S)
2. Clique no botÃ£o verde "Start" (â–¶ï¸)
3. Observe os listeners em tempo real
4. Aguarde conclusÃ£o
5. Analise os resultados

---

## ğŸ“Š CenÃ¡rios de Teste Detalhados

### ğŸŸ¢ CenÃ¡rio 1: Carga Esparsa (Baseline)

**Objetivo:** Estabelecer a linha base de performance do sistema em condiÃ§Ãµes normais.

**ConfiguraÃ§Ã£o JMeter:**
```
Threads: 10 usuÃ¡rios
Ramp-Up: 30 segundos (1 usuÃ¡rio a cada 3 segundos)
Loop Count: 10 vezes cada
DuraÃ§Ã£o: ~5 minutos
```

**Endpoints a testar:**
- GET /products (listagem)
- GET /status (health check)
- GET /products/{id} (detalhes)

**Resultados Esperados:**
- âœ… Tempo mÃ©dio: < 100ms
- âœ… Taxa de erro: 0%
- âœ… Throughput: 3-5 req/s
- âœ… CPU: < 30%
- âœ… MemÃ³ria: EstÃ¡vel

**Para o relatÃ³rio:** Use este cenÃ¡rio como **referÃªncia** para comparar os outros.

---

### ğŸŸ¡ CenÃ¡rio 2: Carga Crescente

**Objetivo:** Testar escalabilidade com crescimento gradual de usuÃ¡rios (simula crescimento de negÃ³cio).

**ConfiguraÃ§Ã£o JMeter:**
```
Threads: 500 usuÃ¡rios
Ramp-Up: 120 segundos (4 usuÃ¡rios por segundo)
Loop Count: 5 vezes cada
DuraÃ§Ã£o: ~10-15 minutos
```

**DistribuiÃ§Ã£o de RequisiÃ§Ãµes:**
- 40% GET /products (leitura Ã© mais comum)
- 20% POST /products (criar)
- 20% PUT /products/{id} (atualizar)
- 10% DELETE /products/{id} (deletar)
- 10% GET /heavy-cpu (operaÃ§Ãµes pesadas)

**Resultados Esperados:**
- âš ï¸ Tempo mÃ©dio: 200-500ms
- âš ï¸ Taxa de erro: < 5%
- âš ï¸ Throughput: 30-50 req/s
- âš ï¸ CPU: 60-80%
- âš ï¸ MemÃ³ria: Aumenta gradualmente

**Para o relatÃ³rio:** Identifique em que momento o sistema comeÃ§a a degradar.

---

### ğŸ”´ CenÃ¡rio 3: Rajada de Carga (Spike Test)

**Objetivo:** Testar comportamento sob pico sÃºbito de acessos (simula Black Friday, promoÃ§Ã£o viral).

**ConfiguraÃ§Ã£o JMeter:**
```
Threads: 1000 usuÃ¡rios
Ramp-Up: 10 segundos (100 usuÃ¡rios por segundo!)
Loop Count: 1 vez
DuraÃ§Ã£o: ~2-3 minutos (pico intenso e curto)
```

**DistribuiÃ§Ã£o de RequisiÃ§Ãµes:**
- 50% GET /products (usuÃ¡rios navegando)
- 30% GET /many-items (carregamento pesado)
- 20% GET /heavy-io (operaÃ§Ãµes lentas)

**Resultados Esperados:**
- âŒ Tempo mÃ©dio: 1-3 segundos (ou mais)
- âŒ Taxa de erro: 10-30% (esperado!)
- âŒ Throughput: Varia muito
- âŒ CPU: 100%
- âŒ MemÃ³ria: Pico alto
- âŒ PossÃ­veis timeouts e conexÃµes recusadas

**Para o relatÃ³rio:** Documente os limites do sistema e pontos de falha.

---

## ğŸ“ˆ MÃ©tricas Importantes para o RelatÃ³rio

### MÃ©tricas BÃ¡sicas

| MÃ©trica | DescriÃ§Ã£o | Como Interpretar |
|---------|-----------|------------------|
| **Average** | Tempo mÃ©dio de resposta | Quanto menor, melhor |
| **Median** | Valor do meio (50% percentil) | Representa experiÃªncia "tÃ­pica" |
| **90% Line** | 90Âº percentil | 90% dos usuÃ¡rios tiveram resposta mais rÃ¡pida |
| **95% Line** | 95Âº percentil | Importante para SLA |
| **99% Line** | 99Âº percentil | Identifica outliers |
| **Min/Max** | Tempo mÃ­nimo e mÃ¡ximo | Mostra variaÃ§Ã£o |
| **Error %** | Percentual de erros | Deve ser < 1% idealmente |
| **Throughput** | RequisiÃ§Ãµes por segundo | Quantas req/s o servidor aguenta |
| **KB/sec** | Dados transferidos por segundo | Importante para /many-items |

### MÃ©tricas AvanÃ§adas

- **Desvio PadrÃ£o**: Mede consistÃªncia (baixo = consistente, alto = variÃ¡vel)
- **LatÃªncia de ConexÃ£o**: Tempo para estabelecer conexÃ£o TCP
- **Tempo de Primeira Resposta**: Time To First Byte (TTFB)

---

## ğŸ“Š Tabelas e GrÃ¡ficos para o RelatÃ³rio

### Tabela 1: ComparaÃ§Ã£o de CenÃ¡rios

```
| CenÃ¡rio       | Threads | Tempo MÃ©dio | Mediana | 90% | Erro% | Throughput |
|---------------|---------|-------------|---------|-----|-------|------------|
| Esparsa       | 10      | 45ms       | 42ms    | 58ms| 0%    | 4.2 req/s  |
| Crescente     | 500     | 234ms      | 198ms   | 456ms| 2.1%  | 38.5 req/s |
| Rajada        | 1000    | 1250ms     | 987ms   | 2340ms| 15.3% | 52.1 req/s |
```

### Tabela 2: AnÃ¡lise por Endpoint

```
| Endpoint      | Tempo MÃ©dio | Taxa Erro | ObservaÃ§Ãµes |
|---------------|-------------|-----------|-------------|
| GET /products | 45ms       | 0%        | PerformÃ¡tico |
| POST /products| 67ms       | 0.5%      | Inserts rÃ¡pidos |
| GET /heavy-cpu| 1850ms     | 3%        | CPU 100% |
| GET /heavy-io | 3002ms     | 5%        | Limite de conexÃµes |
| GET /many-items| 890ms     | 1%        | Muitos dados |
```

### GrÃ¡ficos Recomendados

1. **Tempo de Resposta vs NÃºmero de UsuÃ¡rios**
   - Eixo X: UsuÃ¡rios simultÃ¢neos (10, 100, 200, 500, 1000)
   - Eixo Y: Tempo mÃ©dio de resposta (ms)
   - Mostra degradaÃ§Ã£o com carga

2. **Taxa de Erro vs Carga**
   - Eixo X: NÃºmero de threads
   - Eixo Y: Percentual de erros
   - Identifica ponto de ruptura

3. **Throughput ao Longo do Tempo**
   - Eixo X: Tempo (minutos)
   - Eixo Y: RequisiÃ§Ãµes/segundo
   - Mostra estabilidade

4. **Uso de Recursos do Servidor**
   - CPU % ao longo do tempo
   - MemÃ³ria RAM ao longo do tempo
   - Correlaciona com carga

5. **DistribuiÃ§Ã£o de Tempos de Resposta (Percentis)**
   - GrÃ¡fico de barras: 50%, 75%, 90%, 95%, 99%
   - Para cada cenÃ¡rio

---

## ğŸ¯ AnÃ¡lise e ConclusÃµes para o RelatÃ³rio

### O que escrever:

#### 1. IntroduÃ§Ã£o
- DescriÃ§Ã£o da aplicaÃ§Ã£o
- Tecnologias utilizadas (Node.js, Express, SQLite)
- Objetivos dos testes

#### 2. Metodologia
- Ferramenta: Apache JMeter
- Ambiente: local/nuvem, configuraÃ§Ãµes de hardware
- CenÃ¡rios testados (descrever cada um)

#### 3. Resultados
- Apresentar tabelas e grÃ¡ficos
- Descrever comportamento em cada cenÃ¡rio
- MÃ©tricas coletadas

#### 4. AnÃ¡lise
- **Carga Esparsa**: "Sistema respondeu de forma satisfatÃ³ria, com tempos de resposta baixos e zero erros. Baseline estabelecido em 45ms."
- **Carga Crescente**: "Com 500 usuÃ¡rios, sistema manteve performance aceitÃ¡vel (234ms) mas com 2.1% de erros, indicando limite de conexÃµes."
- **Rajada**: "Sob 1000 usuÃ¡rios simultÃ¢neos, sistema sofreu degradaÃ§Ã£o significativa (1250ms mÃ©dio) com 15.3% erros. Identifica necessidade de escalabilidade."

#### 5. Gargalos Identificados
- CPU: Endpoint /heavy-cpu satura CPU a 100%
- I/O: /heavy-io limitado por conexÃµes simultÃ¢neas
- Banda: /many-items consome muita largura de banda
- Banco: SQLite pode ser gargalo (nÃ£o tem conexÃµes paralelas eficientes)

#### 6. RecomendaÃ§Ãµes
- Implementar cache (Redis) para /products
- Adicionar rate limiting para prevenir sobrecarga
- Usar banco de dados mais robusto (PostgreSQL, MySQL)
- Escalar horizontalmente (mÃºltiplas instÃ¢ncias)
- Adicionar CDN para conteÃºdo estÃ¡tico
- Implementar queue system para operaÃ§Ãµes pesadas

#### 7. ConclusÃ£o
- Sistema adequado para carga baixa/mÃ©dia
- Necessita melhorias para escalar
- Testes identificaram limites claros
- PrÃ³ximos passos definidos

---

## ğŸš€ Dicas para Impressionar no Trabalho

1. **Varie os testes**: Teste cada endpoint isoladamente tambÃ©m
2. **Monitore o servidor**: Use Task Manager/htop durante testes e tire prints
3. **Documente tudo**: Prints do JMeter, grÃ¡ficos coloridos, tabelas bem formatadas
4. **Compare antes/depois**: Se fizer alguma otimizaÃ§Ã£o, mostre a diferenÃ§a
5. **Seja crÃ­tico**: Analise nÃ£o sÃ³ os nÃºmeros, mas o **porquÃª** deles
6. **Proponha soluÃ§Ãµes**: Mostre que entende como melhorar

---

## âœ… Checklist Final

- [ ] Servidor rodando (`npm start`)
- [ ] Banco populado com 5000 produtos (`npm run seed`)
- [ ] JMeter instalado e testado
- [ ] 3 Thread Groups criados (esparsa, crescente, rajada)
- [ ] Listeners configurados
- [ ] Testes executados e resultados salvos
- [ ] Prints/screenshots capturados
- [ ] GrÃ¡ficos gerados
- [ ] Tabelas criadas
- [ ] RelatÃ³rio escrito
- [ ] AnÃ¡lise crÃ­tica feita
- [ ] RecomendaÃ§Ãµes propostas

---

**Boa sorte no desafio MAD! ğŸ“ğŸš€**
