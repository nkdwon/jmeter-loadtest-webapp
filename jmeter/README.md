# ğŸ§ª Testes de Carga com Apache JMeter

Esta pasta contÃ©m todos os arquivos relacionados aos testes de carga realizados com Apache JMeter.

---

## ğŸ“ Estrutura de Arquivos

```
jmeter/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ plano-testes-basico.jmx    # Plano de testes com 3 cenÃ¡rios configurados
â”‚
â””â”€â”€ test-results/
    â”œâ”€â”€ teste1-carga-esparsa/      # Teste 1: Carga Esparsa (10 usuÃ¡rios)
    â”‚   â”œâ”€â”€ dados/
    â”‚   â”‚   â””â”€â”€ teste1-summary.csv
    â”‚   â””â”€â”€ prints/
    â”‚       â”œâ”€â”€ teste1_summary_report.png
    â”‚       â””â”€â”€ teste1_results_table.png
    â”‚       âš ï¸  NOTA: Falta teste1_response_time_graph.png
    â”‚
    â”œâ”€â”€ teste2-carga-crescente/    # Teste 2: Carga Crescente (500 usuÃ¡rios)
    â”‚   â”œâ”€â”€ dados/
    â”‚   â”‚   â””â”€â”€ teste2-summary.csv
    â”‚   â””â”€â”€ prints/
    â”‚       â”œâ”€â”€ teste2_summary_report.png
    â”‚       â”œâ”€â”€ teste2_response_time_graph.png
    â”‚       â”œâ”€â”€ teste2_results_table.png
    â”‚       â””â”€â”€ teste2_results_table_errors.png
    â”‚
    â”œâ”€â”€ teste3-rajada-carga/       # Teste 3: Rajada de Carga (1000 usuÃ¡rios)
    â”‚   â”œâ”€â”€ dados/
    â”‚   â”‚   â””â”€â”€ teste3-summary.csv
    â”‚   â””â”€â”€ prints/
    â”‚       â”œâ”€â”€ teste3_summary_report.png
    â”‚       â”œâ”€â”€ teste3_response_time_graph.png
    â”‚       â”œâ”€â”€ teste3_results_table.png
    â”‚       â””â”€â”€ teste3_results_table_errors.png
    â”‚
    â””â”€â”€ analysis/
        â”œâ”€â”€ gerar_graficos.py      # Script Python para gerar grÃ¡ficos comparativos
        â””â”€â”€ graficos/
            â”œâ”€â”€ 01-comparativo-geral.png
            â”œâ”€â”€ 02-escalabilidade.png
            â”œâ”€â”€ 03-performance-endpoints.png
            â””â”€â”€ 04-identificacao-gargalos.png
```

---

## ğŸš€ Como Executar os Testes

### PrÃ©-requisitos

1. **Apache JMeter instalado**
   - Download: https://jmeter.apache.org/download_jmeter.cgi
   - VersÃ£o usada: 5.6.3

2. **Servidor da aplicaÃ§Ã£o rodando**
   ```bash
   npm install
   npm run seed  # Popular banco de dados
   npm start     # Iniciar servidor na porta 3000
   ```

### Executando os Testes

#### OpÃ§Ã£o 1: Interface GrÃ¡fica (GUI Mode)

```bash
# Windows
jmeter.bat

# Linux/Mac
jmeter.sh
```

Depois:
1. Abrir arquivo: `jmeter/config/plano-testes-basico.jmx`
2. Configurar listeners desejados (Summary Report, Graph Results, etc.)
3. Clicar no botÃ£o â–¶ï¸ (Start) para executar
4. Salvar resultados em CSV
5. Capturar screenshots dos listeners

#### OpÃ§Ã£o 2: Linha de Comando (Recomendado para testes reais)

```bash
# Teste 1: Carga Esparsa
jmeter -n -t config/plano-testes-basico.jmx -l results/teste1.jtl -e -o results/teste1-report

# Teste 2: Carga Crescente
jmeter -n -t config/plano-testes-basico.jmx -l results/teste2.jtl -e -o results/teste2-report

# Teste 3: Rajada de Carga
jmeter -n -t config/plano-testes-basico.jmx -l results/teste3.jtl -e -o results/teste3-report
```

**ParÃ¢metros:**
- `-n`: Modo non-GUI (sem interface)
- `-t`: Arquivo do plano de testes
- `-l`: Arquivo de log de resultados (.jtl)
- `-e`: Gerar relatÃ³rio HTML
- `-o`: Pasta de saÃ­da do relatÃ³rio

---

## ğŸ“Š ConfiguraÃ§Ã£o dos Testes

### Plano de Testes: `plano-testes-basico.jmx`

O plano contÃ©m **3 Thread Groups** (grupos de usuÃ¡rios):

#### **Teste 1: Carga Esparsa**
- **UsuÃ¡rios**: 10
- **Ramp-up**: 30 segundos (1 usuÃ¡rio a cada 3s)
- **IteraÃ§Ãµes**: 10 loops
- **DuraÃ§Ã£o**: ~1 minuto
- **Objetivo**: Estabelecer baseline de performance

#### **Teste 2: Carga Crescente**
- **UsuÃ¡rios**: 500
- **Ramp-up**: 120 segundos (~4 usuÃ¡rios/segundo)
- **IteraÃ§Ãµes**: 10 loops
- **DuraÃ§Ã£o**: ~4 minutos
- **Objetivo**: Testar escalabilidade com carga crescente

#### **Teste 3: Rajada de Carga**
- **UsuÃ¡rios**: 1000
- **Ramp-up**: 10 segundos (100 usuÃ¡rios/segundo)
- **IteraÃ§Ãµes**: 3 loops
- **DuraÃ§Ã£o**: ~30 segundos
- **Objetivo**: Simular pico sÃºbito de acessos (spike test)

### Endpoints Testados

Cada thread group faz requisiÃ§Ãµes para:

1. **GET /products** - Listagem de produtos
2. **POST /products** - CriaÃ§Ã£o de produto
3. **GET /heavy-cpu** - Processamento intensivo (50M iteraÃ§Ãµes)
4. **GET /heavy-io** - I/O bloqueante (delay 3s)
5. **GET /many-items** - TransferÃªncia de dados (50k itens)

---

## ğŸ“ˆ Gerando GrÃ¡ficos Comparativos

### Script Python: `analysis/gerar_graficos.py`

Este script lÃª os CSVs dos 3 testes e gera 4 grÃ¡ficos comparativos.

#### InstalaÃ§Ã£o de DependÃªncias

```bash
pip install matplotlib numpy pandas seaborn
```

#### Executando o Script

```bash
cd jmeter/test-results/analysis
python gerar_graficos.py
```

#### GrÃ¡ficos Gerados

1. **01-comparativo-geral.png**
   - 4 subgrÃ¡ficos comparando os 3 testes
   - MÃ©tricas: Taxa de erro, Tempo mÃ©dio, Throughput, Total de requisiÃ§Ãµes

2. **02-escalabilidade.png**
   - 2 grÃ¡ficos de linha mostrando escalabilidade
   - Taxa de erro vs UsuÃ¡rios
   - Throughput vs UsuÃ¡rios

3. **03-performance-endpoints.png**
   - Desempenho por endpoint nos Testes 2 e 3
   - Tempo mÃ©dio vs Taxa de erro

4. **04-identificacao-gargalos.png**
   - Ranking visual dos gargalos identificados
   - GrÃ¡fico de barras horizontal

### SaÃ­da do Script

```
ğŸ“Š GrÃ¡ficos disponÃ­veis:
   1. 01-comparativo-geral.png
   2. 02-escalabilidade.png
   3. 03-performance-endpoints.png
   4. 04-identificacao-gargalos.png

================================================================================
                            TABELA RESUMO DOS TESTES
================================================================================
MÃ©trica                   Teste 1 (10u)        Teste 2 (500u)       Teste 3 (1000u)
--------------------------------------------------------------------------------
UsuÃ¡rios SimultÃ¢neos      10                   500                  1000
Total de RequisiÃ§Ãµes      200                  5000                 3000
Tempo MÃ©dio (ms)          1                    12292                2968
Taxa de Erro (%)          0.0                  25.52                39.27
Throughput (req/s)        7.42                 18.69                122.26
================================================================================
```

---

## ğŸ“‹ Listeners Configurados no JMeter

Para cada teste, os seguintes listeners foram usados:

### 1. Summary Report
- MÃ©tricas gerais: mÃ©dia, mediana, min, max, erro%
- Screenshot salvo como: `testeX_summary_report.png`

### 2. Graph Results
- GrÃ¡fico de tempo de resposta ao longo do tempo
- Screenshot salvo como: `testeX_response_time_graph.png`
- âš ï¸ **NOTA**: Falta captura do Teste 1

### 3. View Results in Table
- Tabela detalhada de cada requisiÃ§Ã£o
- Screenshot salvo como: `testeX_results_table.png`

### 4. View Results Tree (apenas Testes 2 e 3)
- Detalhes dos erros encontrados
- Screenshot salvo como: `testeX_results_table_errors.png`

---

## ğŸ’¾ Exportando Resultados

### Via Interface GrÃ¡fica

1. ApÃ³s executar o teste, clicar com botÃ£o direito no listener
2. Selecionar **"Save Table Data"**
3. Escolher formato CSV
4. Salvar com nome descritivo (ex: `teste1-summary.csv`)

### Via Linha de Comando

Os resultados sÃ£o salvos automaticamente com o parÃ¢metro `-l`:

```bash
jmeter -n -t config/plano-testes-basico.jmx -l teste1-results.jtl
```

---

## ğŸ”§ Dicas de Uso

### Performance do JMeter

- **Modo GUI**: Use apenas para configurar e debug
- **Modo CLI**: Use para testes reais (melhor performance)
- **MemÃ³ria**: Aumentar heap se necessÃ¡rio: `export JVM_ARGS="-Xms1g -Xmx4g"`

### MÃ©tricas Importantes

- **Tempo de Resposta**: Mediana Ã© mais confiÃ¡vel que mÃ©dia
- **Taxa de Erro**: >5% indica problemas sÃ©rios
- **Throughput**: RequisiÃ§Ãµes por segundo (quanto maior, melhor)
- **Percentis**: 90Âº, 95Âº, 99Âº percentil mostram experiÃªncia do usuÃ¡rio

### Boas PrÃ¡ticas

1. Sempre fazer testes com modo non-GUI para resultados reais
2. Executar mÃºltiplas iteraÃ§Ãµes para mÃ©dia estatÃ­stica
3. Monitorar recursos do servidor (CPU, memÃ³ria, I/O)
4. Documentar configuraÃ§Ã£o do ambiente de teste
5. Salvar tanto CSVs quanto screenshots

---

## ğŸ“ Resultados Obtidos

Consulte a pasta `docs/` para anÃ¡lise completa dos resultados, insights e recomendaÃ§Ãµes tÃ©cnicas.

**Resumo rÃ¡pido:**

| Teste | UsuÃ¡rios | RequisiÃ§Ãµes | Erro | Tempo MÃ©dio | Throughput |
|-------|----------|-------------|------|-------------|------------|
| Teste 1 | 10 | 200 | 0.00% âœ… | 1ms | 7.42 req/s |
| Teste 2 | 500 | 5.000 | 25.52% âš ï¸ | 12.292ms | 18.69 req/s |
| Teste 3 | 1.000 | 3.000 | 39.27% ğŸ”´ | 2.968ms | 122.26 req/s |

**ConclusÃ£o**: Sistema suporta atÃ© ~500 usuÃ¡rios simultÃ¢neos antes de degradaÃ§Ã£o crÃ­tica.

---

_Para anÃ¡lise detalhada, insights tÃ©cnicos e estrutura do relatÃ³rio, consulte `docs/README.md`_
