# üìä An√°lise de Resultados dos Testes de Carga
---

## üéØ Resumo Executivo

Foram realizados **3 testes de carga** na aplica√ß√£o Node.js/Express com banco SQLite:

| Teste | Cen√°rio | Usu√°rios | Requisi√ß√µes | Taxa de Erro | Tempo M√©dio | Throughput |
|-------|---------|----------|-------------|--------------|-------------|------------|
| **Teste 1** | Carga Esparsa | 10 | 200 | **0.00%** ‚úÖ | 1ms | 7.42 req/s |
| **Teste 2** | Carga Crescente | 500 | 5.000 | **25.52%** ‚ö†Ô∏è | 12.292ms | 18.69 req/s |
| **Teste 3** | Rajada de Carga | 1.000 | 3.000 | **39.27%** üî¥ | 2.968ms | 122.26 req/s |

### Conclus√£o Geral

O sistema demonstrou **comportamento n√£o-linear** sob carga:
- ‚úÖ **Excelente** com at√© 10 usu√°rios (0% erro)
- ‚ö†Ô∏è **Degrada√ß√£o aceit√°vel** entre 400-500 usu√°rios (25% erro)
- üî¥ **Degrada√ß√£o cr√≠tica** com 1000+ usu√°rios (39% erro)

**Capacidade estimada**: ~500 usu√°rios simult√¢neos antes de falha cr√≠tica.

---

## üìä Resultados Detalhados

### Teste 1: Carga Esparsa (10 usu√°rios)

**Objetivo**: Estabelecer baseline de performance em condi√ß√µes ideais.

#### Configura√ß√£o
- **Usu√°rios**: 10
- **Ramp-up**: 30 segundos (1 usu√°rio a cada 3s)
- **Itera√ß√µes**: 10 loops por usu√°rio
- **Dura√ß√£o total**: ~1 minuto
- **Total de requisi√ß√µes**: 200

#### M√©tricas Obtidas

| M√©trica | Valor |
|---------|-------|
| Requisi√ß√µes totais | 200 |
| Taxa de erro | **0.00%** ‚úÖ |
| Tempo m√©dio | **1ms** |
| Tempo m√≠nimo | 0ms |
| Tempo m√°ximo | 69ms |
| Throughput | 7.42 req/s |
| Dados transferidos | 1.18 MB |
| Taxa de transfer√™ncia | 46.75 KB/s |

#### An√°lise e Insights

‚úÖ **Sistema funcionando perfeitamente em carga leve**

**Por que 0% de erro?**
- Apenas 10 usu√°rios simult√¢neos n√£o saturam os recursos
- SQLite suporta tranquilamente 10 conex√µes de leitura
- CPU tem capacidade sobressalente
- Sem conten√ß√£o de recursos

**Por que tempo m√©dio de 1ms?**
- Servidor e banco local (sem lat√™ncia de rede)
- Opera√ß√µes simples de CRUD
- Cache de mem√≥ria do sistema operacional
- SQLite muito r√°pido para leituras

**Endpoints testados**:
1. `GET /products` - Listagem de produtos ‚úÖ
2. `POST /products` - Cria√ß√£o de produto ‚úÖ
3. `GET /heavy-cpu` - Processamento intensivo ‚úÖ
4. `GET /heavy-io` - I/O bloqueante ‚úÖ
5. `GET /many-items` - 50k itens ‚úÖ

**Comportamento esperado**: Todos os endpoints responderam dentro do esperado. O sistema tem capacidade sobressalente para processar requisi√ß√µes rapidamente.

**Conclus√£o do Teste 1**: Este √© o **baseline ideal**. O sistema √© capaz de processar requisi√ß√µes com lat√™ncia m√≠nima quando n√£o est√° sob press√£o.

---

### Teste 2: Carga Crescente (500 usu√°rios)

**Objetivo**: Avaliar escalabilidade com aumento gradual de carga.

#### Configura√ß√£o
- **Usu√°rios**: 500
- **Ramp-up**: 120 segundos (~4 usu√°rios/segundo)
- **Itera√ß√µes**: 10 loops por usu√°rio
- **Dura√ß√£o total**: ~4 minutos
- **Total de requisi√ß√µes**: 5.000

#### M√©tricas Obtidas

| M√©trica | Valor |
|---------|-------|
| Requisi√ß√µes totais | 5.000 |
| Taxa de erro | **25.52%** ‚ö†Ô∏è |
| Tempo m√©dio | **12.292ms** |
| Tempo m√≠nimo | 0ms |
| Tempo m√°ximo | 44.594ms |
| Throughput | 18.69 req/s |
| Dados transferidos | 18.62 MB |
| Taxa de transfer√™ncia | 77.57 KB/s |

#### An√°lise e Insights

‚ö†Ô∏è **Sistema apresentou degrada√ß√£o significativa**

**Por que 25.52% de erro?**

Esta taxa de erro N√ÉO √© falha do teste - √© uma **descoberta importante** sobre os limites do sistema!

**Gargalos identificados**:

1. **CPU (31.84% erro em /heavy-cpu)**
   - Endpoint que faz 50 milh√µes de itera√ß√µes
   - Node.js single-threaded n√£o consegue processar
   - Requisi√ß√µes excedem timeout padr√£o do JMeter (20s)
   - **Impacto**: ALTO

2. **SQLite - Escrita Concorrente (19.44% erro em POST /products)**
   - SQLite usa lock de escrita (write-ahead log)
   - N√£o suporta m√∫ltiplas escritas simult√¢neas
   - 500 usu√°rios tentando criar produtos ao mesmo tempo
   - Muitas requisi√ß√µes ficam bloqueadas aguardando lock
   - **Impacto**: M√âDIO

3. **Conex√µes (taxa de erro distribu√≠da)**
   - Limite padr√£o de conex√µes TCP sendo atingido
   - Sistema operacional come√ßa a rejeitar conex√µes
   - **Impacto**: BAIXO (neste teste)

**Por que tempo m√©dio aumentou 12.000x?**

De 1ms (Teste 1) para 12.292ms (Teste 2) - crescimento n√£o-linear!

**Motivos**:
- Conten√ß√£o de recursos (CPU, mem√≥ria, I/O)
- Filas de espera (SQLite lock, event loop Node.js)
- Timeouts e retentativas
- Context switching do sistema operacional

**Comportamento por endpoint**:

| Endpoint | Taxa de Erro | Tempo M√©dio | An√°lise |
|----------|--------------|-------------|---------|
| GET /products | ~10% | Baixo | Leitura no SQLite, sem lock |
| POST /products | **19.44%** | Alto | Escrita bloqueada por lock |
| GET /heavy-cpu | **31.84%** | Alt√≠ssimo | Timeout por processamento |
| GET /heavy-io | ~15% | M√©dio | Delay de 3s causa ac√∫mulo |
| GET /many-items | ~8% | Baixo | Rede n√£o √© gargalo |

**Conclus√£o do Teste 2**: O sistema come√ßa a **degradar** entre 400-500 usu√°rios. CPU e SQLite s√£o os principais gargalos. Taxa de erro de 25% indica que 1 em cada 4 requisi√ß√µes falha - **inaceit√°vel para produ√ß√£o**.

---

### Teste 3: Rajada de Carga (1000 usu√°rios)

**Objetivo**: Simular pico s√∫bito de acessos (spike test / stress test).

#### Configura√ß√£o
- **Usu√°rios**: 1.000
- **Ramp-up**: 10 segundos (100 usu√°rios/segundo)
- **Itera√ß√µes**: 3 loops por usu√°rio
- **Dura√ß√£o total**: ~30 segundos
- **Total de requisi√ß√µes**: 3.000

#### M√©tricas Obtidas

| M√©trica | Valor |
|---------|-------|
| Requisi√ß√µes totais | 3.000 |
| Taxa de erro | **39.27%** üî¥ |
| Tempo m√©dio | **2.968ms** |
| Tempo m√≠nimo | 0ms |
| Tempo m√°ximo | 12.722ms |
| Throughput | **122.26 req/s** |
| Dados transferidos | 7.05 MB |
| Taxa de transfer√™ncia | 294.55 KB/s |

#### An√°lise e Insights

üî¥ **Sistema em estado cr√≠tico**

**Por que 39.27% de erro (mais que Teste 2)?**

Apesar de ter MENOS requisi√ß√µes totais (3.000 vs 5.000), a taxa de erro √© MAIOR!

**Motivo**: N√£o √© a quantidade total, mas a **velocidade de chegada**!

- Teste 2: 500 usu√°rios em 120s = ~4 usu√°rios/segundo
- Teste 3: 1000 usu√°rios em 10s = **100 usu√°rios/segundo** (25x mais r√°pido!)

**Novo gargalo dominante**: **Limite de Conex√µes Simult√¢neas**

1. **Conex√µes TCP (39% erro em TODOS os endpoints)**
   - Sistema operacional tem limite de conex√µes simult√¢neas
   - Aplica√ß√£o Node.js tem limite de sockets
   - Chegando 100 usu√°rios/segundo, n√£o d√° tempo de processar
   - Conex√µes s√£o **rejeitadas antes mesmo de chegar na aplica√ß√£o**
   - **Impacto**: CR√çTICO

**Por que tempo m√©dio DIMINUIU? (2.968ms vs 12.292ms)**

Isso parece contra-intuitivo, mas faz sentido:

**Explica√ß√£o**:
- Muitas requisi√ß√µes **falharam rapidamente** (connection refused, timeout r√°pido)
- Requisi√ß√µes que falharam t√™m tempo baixo (n√£o processam nada)
- Apenas as requisi√ß√µes **que conseguiram passar** demoraram
- M√©dia foi puxada para baixo pelos erros r√°pidos

**Analogia**: Fila de restaurante lotado:
- Teste 2: Fila grande, mas todos eventualmente s√£o atendidos (devagar)
- Teste 3: Fila t√£o grande que porteiro barra a maioria na porta (r√°pido, mas n√£o atende)

**Por que throughput AUMENTOU 6.5x? (122 req/s vs 18.69 req/s)**

**Throughput = requisi√ß√µes/segundo (incluindo erros!)**

- Teste 2: 5.000 req em ~267s = 18.69 req/s
- Teste 3: 3.000 req em ~24s = 122.26 req/s

O sistema est√° processando (ou rejeitando) requisi√ß√µes **muito mais r√°pido**.

**Conclus√£o do Teste 3**: O sistema **n√£o aguenta** 1000 usu√°rios simult√¢neos em rajada. Quase 40% de falha √© **catastr√≥fico** para usu√°rios reais. O gargalo mudou de CPU/SQLite para **limite de conex√µes**.

---

## üìà An√°lise Comparativa

### Comportamento N√£o-Linear

```
Usu√°rios:    10    ‚Üí    500    ‚Üí   1000
Erro:      0.00%  ‚Üí  25.52%  ‚Üí  39.27%  (crescimento acelerado)
Tempo:       1ms   ‚Üí  12.292ms ‚Üí  2.968ms  (subiu 12.000x, depois caiu 76%)
Throughput: 7.42  ‚Üí   18.69   ‚Üí 122.26   (aumentou 16x)
```

**Observa√ß√µes**:

1. **Taxa de erro cresceu de forma n√£o-linear**
   - 0 ‚Üí 500 usu√°rios: +25.52%
   - 500 ‚Üí 1000 usu√°rios: +13.75% (menos que dobro)
   - Sistema j√° estava no limite em 500 usu√°rios

2. **Tempo m√©dio teve comportamento an√¥malo**
   - Aumentou 12.000x de 10 para 500 usu√°rios
   - Diminuiu 76% de 500 para 1000 usu√°rios
   - Indica mudan√ßa de gargalo (CPU/SQLite ‚Üí Conex√µes)

3. **Throughput aumentou, mas n√£o significa melhora**
   - Alto throughput com alta taxa de erro = sistema rejeitando r√°pido
   - N√£o √© indicador de sa√∫de do sistema sozinho

### Gr√°ficos Dispon√≠veis

Os gr√°ficos gerados pelo script Python est√£o em:  
`jmeter/test-results/analysis/graficos/`

1. **01-comparativo-geral.png** - Vis√£o geral dos 3 testes
2. **02-escalabilidade.png** - Comportamento de erro e throughput vs usu√°rios
3. **03-performance-endpoints.png** - Desempenho por endpoint
4. **04-identificacao-gargalos.png** - Ranking visual de gargalos

**Use os gr√°ficos 01, 02 e 04 no relat√≥rio!**

---

## üîç Identifica√ß√£o de Gargalos

### Ranking de Gargalos (por impacto)

| #  | Gargalo | Teste Afetado | Taxa de Erro | Severidade |
|----|---------|---------------|--------------|------------|
| 1Ô∏è‚É£ | **Conex√µes Simult√¢neas** | Teste 3 | 39.00% | üî¥ CR√çTICA |
| 2Ô∏è‚É£ | **CPU (Heavy-CPU endpoint)** | Teste 2 | 31.84% | üü† ALTA |
| 3Ô∏è‚É£ | **SQLite (Escrita concorrente)** | Teste 2 | 19.44% | üü° M√âDIA |

### Matriz de Impacto

| Gargalo | Impacto em Performance | Impacto em Disponibilidade | Facilidade de Resolver |
|---------|------------------------|----------------------------|------------------------|
| Conex√µes | Alto (39% erro) | Cr√≠tico (usu√°rios rejeitados) | M√©dio (config + clustering) |
| CPU | Muito Alto (timeout) | Alto (31% erro) | F√°cil (clustering, worker threads) |
| SQLite | M√©dio (bloqueio) | M√©dio (19% erro) | Dif√≠cil (migrar para PostgreSQL) |

### Explica√ß√£o de Cada Gargalo

#### 1Ô∏è‚É£ Conex√µes Simult√¢neas (Cr√≠tico)

**O que √©:**
- Limite de conex√µes TCP simult√¢neas que o servidor aceita
- Configura√ß√£o do sistema operacional (ulimit)
- Limite interno da aplica√ß√£o Node.js

**Por que falha:**
- 1000 usu√°rios chegam em 10 segundos
- Servidor n√£o consegue abrir tantos sockets
- Sistema operacional rejeita novas conex√µes (EMFILE, ENFILE)

**Como resolver:**
- Aumentar `ulimit -n` no sistema operacional
- Configurar `server.maxConnections` no Node.js
- Implementar **clustering** (m√∫ltiplos processos)
- Adicionar **load balancer** (distribuir carga)

#### 2Ô∏è‚É£ CPU - Heavy-CPU (Alto)

**O que √©:**
- Endpoint `/heavy-cpu` faz 50 milh√µes de itera√ß√µes
- Simula processamento intensivo (c√°lculos, algoritmos)
- Node.js single-threaded bloqueia event loop

**Por que falha:**
- Processamento leva mais de 20 segundos
- JMeter d√° timeout
- Outras requisi√ß√µes ficam bloqueadas esperando

**Como resolver:**
- **Worker Threads** (Node.js) - processamento paralelo
- **Clustering** - m√∫ltiplos processos Node.js
- **Fila de processamento** (Redis/Bull) - processar assincronamente
- **Otimizar algoritmo** - reduzir itera√ß√µes

#### 3Ô∏è‚É£ SQLite - Escrita Concorrente (M√©dio)

**O que √©:**
- SQLite usa lock exclusivo para escrita
- Apenas 1 transa√ß√£o de escrita por vez
- Outras escritas ficam bloqueadas

**Por que falha:**
- 500 usu√°rios tentam criar produtos simultaneamente
- Maioria fica aguardando lock
- Timeout ou erro SQLITE_BUSY

**Como resolver:**
- **Migrar para PostgreSQL ou MySQL**
  - Suportam escrita concorrente
  - MVCC (Multi-Version Concurrency Control)
  - Melhor para aplica√ß√µes multi-usu√°rio
- **Cache de escrita** (Redis) - buffer antes de gravar
- **Fila de escrita** - serializar opera√ß√µes

---

## üõ†Ô∏è Recomenda√ß√µes T√©cnicas

### Priorizadas por Severidade

#### üî¥ Severidade CR√çTICA (Implementar Imediatamente)

**1. Aumentar Limite de Conex√µes**

**Problema**: 39% de erro por limite de conex√µes TCP

**Solu√ß√£o**:
```javascript
// server.js
const server = app.listen(PORT);
server.maxConnections = 2000; // Aumentar de padr√£o (~512)
```

```bash
# Sistema operacional (Linux)
ulimit -n 10000  # Aumentar limite de file descriptors
```

**Impacto esperado**: Reduzir taxa de erro de 39% para ~15%

**Esfor√ßo**: Baixo (configura√ß√£o)

---

**2. Implementar Clustering**

**Problema**: Node.js single-threaded n√£o aproveita m√∫ltiplos cores da CPU

**Solu√ß√£o**:
```javascript
// cluster.js
const cluster = require('cluster');
const os = require('os');

if (cluster.isMaster) {
  const numCPUs = os.cpus().length;
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }
} else {
  require('./server.js');
}
```

**Impacto esperado**: 4x capacidade de processamento (em CPU quad-core)

**Esfor√ßo**: Baixo (c√≥digo simples)

---

**3. Migrar para PostgreSQL ou MySQL**

**Problema**: SQLite n√£o suporta escrita concorrente (19% erro em POST)

**Solu√ß√£o**:
- Migrar de SQLite para PostgreSQL
- Usar pool de conex√µes (pg-pool)
- MVCC resolve problema de lock

**Impacto esperado**: Reduzir erro de escrita de 19% para <2%

**Esfor√ßo**: M√©dio (refatora√ß√£o de c√≥digo)

---

#### üü† Severidade ALTA (Implementar em M√©dio Prazo)

**4. Implementar Cache com Redis**

**Problema**: Leituras repetidas sobrecarregam banco

**Solu√ß√£o**:
```javascript
const redis = require('redis');
const client = redis.createClient();

app.get('/products', async (req, res) => {
  const cached = await client.get('products');
  if (cached) return res.json(JSON.parse(cached));
  
  const products = await db.all('SELECT * FROM products');
  await client.setex('products', 60, JSON.stringify(products));
  res.json(products);
});
```

**Impacto esperado**: 80% redu√ß√£o de carga no banco

**Esfor√ßo**: M√©dio

---

**5. Adicionar Load Balancer (Nginx)**

**Problema**: Single point of failure, sem distribui√ß√£o de carga

**Solu√ß√£o**:
```nginx
upstream backend {
  server localhost:3000;
  server localhost:3001;
  server localhost:3002;
  server localhost:3003;
}

server {
  listen 80;
  location / {
    proxy_pass http://backend;
  }
}
```

**Impacto esperado**: Distribuir carga, aumentar disponibilidade

**Esfor√ßo**: M√©dio

---

**6. Otimizar Endpoint /heavy-cpu**

**Problema**: 50M itera√ß√µes bloqueiam event loop (31% erro)

**Solu√ß√£o**:
- Usar Worker Threads para processamento paralelo
- Ou implementar fila de processamento (Bull + Redis)
- Ou otimizar algoritmo (reduzir itera√ß√µes)

**Impacto esperado**: Reduzir timeout de 31% para <5%

**Esfor√ßo**: M√©dio

---

#### üü° Severidade M√âDIA (Implementar em Longo Prazo)

**7. Implementar Rate Limiting**

**Problema**: N√£o h√° prote√ß√£o contra spike de requisi√ß√µes

**Solu√ß√£o**:
```javascript
const rateLimit = require('express-rate-limit');

const limiter = rateLimit({
  windowMs: 1 * 60 * 1000, // 1 minuto
  max: 100 // m√°ximo 100 requisi√ß√µes por minuto
});

app.use('/api/', limiter);
```

**Impacto esperado**: Proteger sistema de sobrecarga

**Esfor√ßo**: Baixo

---

**8. Circuit Breaker Pattern**

**Problema**: Cascata de falhas quando sistema est√° sobrecarregado

**Solu√ß√£o**:
- Implementar circuit breaker (biblioteca: opossum)
- Detectar falhas e "abrir circuito" temporariamente
- Retornar erro r√°pido ao inv√©s de deixar requisi√ß√µes acumularem

**Impacto esperado**: Degrada√ß√£o graceful, melhor experi√™ncia

**Esfor√ßo**: M√©dio

---

## üí° 5 Insights Principais

**Use estes insights na conclus√£o do relat√≥rio:**

### 1Ô∏è‚É£ Comportamento N√£o-Linear sob Carga

**Insight**: O sistema demonstrou degrada√ß√£o n√£o-linear ao aumentar a carga.

**Explica√ß√£o**: Entre 10 e 500 usu√°rios, o tempo m√©dio aumentou **12.000x** (de 1ms para 12.292ms). Por√©m, ao dobrar a carga para 1000 usu√°rios, o tempo m√©dio **melhorou 76%** (caiu para 2.968ms). Esse comportamento aparentemente contra-intuitivo indica que **diferentes gargalos se manifestam em diferentes cen√°rios de carga**.

**Implica√ß√£o**: N√£o √© poss√≠vel prever linearmente como o sistema se comportar√° sob carga crescente. Testes emp√≠ricos s√£o essenciais.

---

### 2Ô∏è‚É£ Gargalos M√∫ltiplos Dependendo do Cen√°rio

**Insight**: O sistema possui m√∫ltiplos gargalos que se tornam dominantes em diferentes padr√µes de carga.

**Explica√ß√£o**:
- Em **carga crescente** (500 usu√°rios, 120s ramp-up): CPU e SQLite s√£o os limitantes principais
- Em **rajadas** (1000 usu√°rios, 10s ramp-up): Limite de conex√µes se torna cr√≠tico

**Implica√ß√£o**: A otimiza√ß√£o deve ser feita pensando em **m√∫ltiplos cen√°rios**, n√£o apenas um tipo de carga.

---

### 3Ô∏è‚É£ Alta Efici√™ncia de Processamento, Baixa Disponibilidade

**Insight**: O sistema demonstrou alta efici√™ncia de processamento (122 req/s no Teste 3, 16x maior que baseline) mas baixa disponibilidade (39% taxa de erro).

**Explica√ß√£o**: O gargalo **n√£o √© velocidade de processamento**, mas **capacidade de aceitar conex√µes simult√¢neas**. As requisi√ß√µes que conseguem entrar s√£o processadas rapidamente, mas muitas s√£o rejeitadas antes mesmo de serem processadas.

**Implica√ß√£o**: Otimizar apenas a velocidade de processamento n√£o resolve o problema. √â necess√°rio aumentar a **capacidade de aceitar conex√µes**.

---

### 4Ô∏è‚É£ Transfer√™ncia de Dados N√£o √© Gargalo

**Insight**: O endpoint `/many-items`, respons√°vel por transferir 50.000 itens (~2-3 MB), apresentou o **menor tempo m√©dio** (1.300ms) entre todos os endpoints testados.

**Explica√ß√£o**: Isso comprova que a rede e serializa√ß√£o JSON n√£o s√£o gargalos do sistema, mesmo sob carga extrema. A transfer√™ncia de grandes volumes de dados √© eficiente.

**Implica√ß√£o**: N√£o √© necess√°rio otimizar serializa√ß√£o ou compress√£o de dados. Foco deve ser em **processamento e conex√µes**.

---

### 5Ô∏è‚É£ Capacidade Estimada do Sistema

**Insight**: Com base nos resultados, estima-se que o sistema suporte entre **400-600 usu√°rios simult√¢neos** antes de degrada√ß√£o cr√≠tica.

**Explica√ß√£o**:
- Teste 1 (10 usu√°rios): 0% erro - **√ìtimo**
- Teste 2 (500 usu√°rios): 25% erro - **Degrada√ß√£o aceit√°vel (limiar)**
- Teste 3 (1000 usu√°rios): 39% erro - **Cr√≠tico**

Interpolando, o sistema come√ßa a degradar significativamente ap√≥s ~400-500 usu√°rios.

**Implica√ß√£o**: Para suportar mais de 500 usu√°rios, √© **essencial** implementar as recomenda√ß√µes t√©cnicas (clustering, PostgreSQL, aumento de conex√µes).
